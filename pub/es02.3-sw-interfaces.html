<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1024" />
    <title>ENGN8537 Lecture 2.3: Embedded Systems Software Interfaces</title>

    <link href="fonts/roboto/stylesheet.css" rel="stylesheet" />
    <link href="fonts/droidsans-mono/stylesheet.css" rel="stylesheet" />
    <link href="fonts/fontello/css/fontello.css" rel="stylesheet" />
    <link href="js/google-code-prettify/prettify.css" rel="stylesheet" />
    <link href="css/es02-3.css" rel="stylesheet" />
</head>

<body class="impress-not-supported">
<div class="fallback-message">
    <p>Your browser <b>doesn't support the features required</b> by impress.js, so you are presented with a simplified version of this presentation.</p>
    <p>For the best experience please use the latest <b>Chrome</b>, <b>Safari</b> or <b>Firefox</b> browser.</p>
</div>

<a class="ov-link" href="#overview">Overview</a>
<a class="notes-link" onclick="impressConsole().open()">Notes</a>

<div id="impress">
    <!-- Title slide -->
    <div id="title" class="step slide" data-x="0" data-y="500">
        <div class="logo">
            <img src='images/ANU_LOGO_cmyk_56mm-large.png' width='200' />
        </div>

        <div class="headbox">
            <p>Research School of Engineering</p>
            <p class="course">ENGN8537: Embedded Systems and Real Time Digital Signal Processing</p>
        </div>
        <div id="say">It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of</div>
        <div class="titlebox">
            <h2>Embedded Systems</h2>
            <h1>Software Interfaces</h1>
        </div>
        <div class="linkbox">
            <a href="?print">print view</a>
        </div>
    </div>

    <div class="step" data-x="866" data-y="0" data-scale="0.5">
        <h1>Operating Environment</h1>
        <ul><li>Operating System</li>
            <li>Libraries</li>
            <li>Runtime</li></ul>
        <div class="notes">Must consider size, complexity, driver availability etc</div>
    </div>

    <div class="step point" data-x='1366' data-y='0' data-scale="0.5">
        <h2>Very Important</h2>
        We will have a whole module later in the course.
    </div>


    <div class="step" data-x="1000" data-y="500" data-scale="0.5">
        <h1>Memory Requirements</h1>
        <ul><li>RAM/Flash usage</li>
            <li>Volatility requirements</li>
            <li>Speed/Latency requirements</li></ul>
        <div class="notes">Will be covered in more depth in the sequel</div>
    </div>

    <div class="step" id="memblocks" data-x='1450' data-y='500' data-scale="0.5">
        <div class="rightbox" style="width:200px" id="m-cache">L1 Cache<br/>L2 Cache<br/>L3&hellip;</div>
        <div class="rightbox" style="width:200px" id="m-ram">RAM</div>
        <div class="rightbox" style="width:200px" id="m-flash">Flash</div>
        <div class="rightbox" style="width:200px" id="m-hdd">Hard Drive</div>
        <div class="rightbox" style="width:200px" id="m-cloud">Network/Cloud</div>
    </div>

    <div class="step" id="cache" data-x='1350' data-y='430' data-scale="0.15">
        <div style="float:right;width:500px">
        <ul><li>Fast access (cycles)</li>
            <li>Tight coupling</li>
            <li>Small capacity (MB)</li>
            <li>Implemented as RAM</li></ul></div>

        <div class="notes">
Most modern CPUs keep recently-accessed data cached in a small amount of memory tightly coupled to the CPU itself. Code rarely controls the cache itself, but can be optimized for good cache performance. L1 Cache is typically accessed in 1-2 CPU cycles while lower level caches are proportionally slower.

In multi-core chips, the lower levels of cache may be shared between cores. This increases
complexity somewhat as the cache has to remain ‘coherent’ across all cores; that is, because cache
data is a copy of RAM data, it exists in at least two places at one and every core must ensure it
accesses the most recent copy.</div>
    </div>

    <div class="step" id="ram" data-x='1350' data-y='485' data-scale="0.15">
        <div style="float:right;width:500px;">
        <ul><li>Static or Dynamic</li>
            <li>Medium capacity (GB)</li>
            <li>Medium access (100's of cycles)</li></ul></div>

        <div class="notes">
RAM is what we typically think of when we think of memory. In an Embedded System, some base amount is required for program variables and the rest may be used for buffering, trading off cost against throughput.

Larger RAM devices (such as Dynamic RAM) require code to execute in order to be initialized.
This causes a “chicken and egg” problem; code needs RAM to execute, but the RAM needs some code to have executed. If a device is designed to use Dynamic RAM, it will typically also include a small amount of Static RAM internal to the device for the sole purpose of supporting this initial execution.
        </div>
    </div>

    <div class="step" id="flash" data-x='1350' data-y='518' data-scale="0.15">
        <div style="float:right;width:500px;">
        <ul><li>Non-volatile</li>
            <li>Large capacity (10s/100s of GB)</li>
            <li>Slow access (1000's of cycles)</li>
            <li>Finite lifetime</li></ul></div>

        <div class="notes">
Flash memory is slowly replacing hard drives as the standard for local, non-volatile memory. It is typically a few orders of magnitude slower than RAM and several orders of magnitude slower than a CPU cache. Flash can only be written a finite number of times before it wears out, so much of the technology behind dealing with this type of memory goes in to avoiding, detecting and/or correcting errors. Premium flash devices include Error Correcting Codes, ECC, which are special portions of memory that contain enough information to not just detect, but even fix 1, 2 or several-bit errors.
        </div>
    </div>

    <div class="step point" data-x='1500' data-y='518' data-scale="0.15">
        <h1>Wear Levelling</h1>
        Flash lifetime is extended by <b>wear levelling</b>. The algorithm chosen dramatically affects device lifetime.

        <div class="notes">Modern flash memory cards such as SD cards may cheat with their wear leveling algorithms. The FAT filesystem that is typically used on such cards writes data across the card in something approaching a round-robin fashion – in essence it does its own wear leveling. The exception to this is the File Allocation Table block which is written every time any other piece of the card is written.

Given that the FAT gets written many more times than any other piece, the memory may choose to only wear level the section of the card where it thinks the FAT will sit. This means that using a filesystem other than FAT on an SD card may reduce its lifespan 10s or 100s of times!</div>
    </div>

    <div class="step" id="hdd" data-x='1350' data-y='552' data-scale="0.15">
        <div style="float:right;width:500px;">
        <ul><li>Non-volatile</li>
            <li>Very Large capacity (1000s of GB)</li>
            <li>Very Slow access (10,000's of cycles)</li>
            <li>Non-deterministic access times</li></ul></div>

        <div class="notes">
Hard Drives, or magnetic storage generally, have been around almost as long as computers themselves. They are still the de-facto standard for high volume, non-volatile storage. They are not often used in Embedded Systems as they are relatively power-hungry and fragile, at least when they are spinning. They also have non-deterministic response time as the magnetic heads need to physically move over the surface of the disk with each new request.
        </div>
    </div>

    <div class="step" id="cloud" data-x='1350' data-y='585' data-scale="0.15">
        <div style="float:right;width:500px;">
        <ul><li>High Reliability</li>
            <li>Very Large capacity (+1000s of GB)</li>
            <li>Very Slow access (1,000,000 cycles)</li>
            <li>Non-deterministic access times</li></ul></div>

        <div class="notes">
Network storage is becoming more fashionable as markets become less about the Embedded Device itself and more about the service it can offer. Having the service state data live externally to the system itself streamlines upgrades and can drive down system costs by centralizing much more of the system than would traditionally be the case.

Network storage has the obvious drawbacks though – the network is a weak link, both in terms of uptime and reliability, but also in terms of security.
        </div>
    </div>


    <div class="step" data-x="866" data-y="1000" data-scale="0.5">
        <h1>Programming Language</h1>
        <ul><li>Library/Driver availability</li>
            <li>Runtime support</li></ul>
        <div class="notes">The choice of programming language(s) is perhaps the most fundamental software architecture choice. A balance must be struck between features, efficiency, reliability, time to market etc.

One of the key points that distinguishes programming languages from each other are whether they are precompiled, Just-in-Time compiled or Interpreted. These three options place restrictions on the locations in which a language may be used and what may be accomplished with code written in that language.</div>
    </div>


    <div class="step" data-x='1366' data-y='850' data-scale="0.5">
        <h1>Compiled</h1>
        <center><img class="naked" src="images/software-interfaces/compiled.png" /></center>
        <div class="notes">Precompiled code is typical of programming languages such as C, C++, ADA etc. Precompiled code doesn’t incur run-time overhead translating the programmer’s wishes to actions, however it offers less flexibility than other options.</div>
    </div>

    <div class="step" data-x='1306' data-y='960' data-scale="0.2">
            <p><b>Compiler:</b> Source Code to Assembly</p>
            <p><b>Assembler:</b> Assembly to Binary. Does not resolve symbols.</p>
            <p>Compiler and Assembler are specific to a particular platform.</p>
        <div class="notes">The compiler takes source code and generates machine language assembly mnemonics (written instructions such as MOV, ADD). The assembler takes this assembly, along with any that has been manually written and generates the binary object files. References to memory locations remain in symbolic form – the object file doesn’t yet know where in memory everything is going to end up.

The compiler and assembler are typically invoked with a single instruction, the intermediate assembly mnemonics are stored in a temporary file and removed upon successful generation of the object file.

The compiler is responsible for most optimizations and generation of platform-specific code. When choosing hardware, it must be selected to be compatible with the target compiler.</div>
    </div>

    <div class="step" data-x='1476' data-y='955' data-scale="0.2">
            <p><b>Linker:</b> Object Files to Executable</p>
            <p>Resolves symbols between object files and libraries.</p>

        <div class="notes">The Linker combines multiple object files (typically one per source file) along with external libraries, joins them all together in a single executable then goes through and resolves all symbols. Symbol resolution is the process of going through the executable, finding instructions that reference memory (load, store, function calls etc.) and inserting the correct memory location in to the instruction.</div>
    </div>


    <div class="step" data-x='1546' data-y='840' data-scale="0.2">
            <div style="float:right;width:700px">
            <p><b>Static Libraries:</b> Function code is &ldquo;cut &amp; paste&rdquo; in to the final executable.</p>
            <p><b>Dynamic Libraries:</b> Function code is kept separate and loaded at run-time.</p>
        <p>Statically linked binaries are faster to load and require no external files on the target. Dynamically linked libraries are smaller and allow libraries to be shared.</p></div>

        <div class="notes">If static libraries are used, all symbols in the executable are resolved and no other item is required for that binary to be executed. This is typically the case for Embedded Systems.

Dynamic libraries (DLLs in Windows-speak, SOs in Linux) have their symbols left unresolved at Link time. The final memory locations for shared symbols are only resolved when the executable is run. This increases start up times but sharing code between executables can reduce overall size.</div>
    </div>

    <div class="step" data-x='1846' data-y='640' data-scale="0.2">
        <h1>Dynamic Linker Example</h1>
        <pre class="card prettyprint">
#include "stdio.h"

int main(int argc, char** argv)
{
    printf("Hello World");
    return 0;
}
        </pre>
    </div>

    <div class="step" data-x='1846' data-y='740' data-scale="0.2">
        <h2>What's in stdio.h</h2>
        <pre class="card prettyprint">
+: grep printf /usr/include/stdio.h
extern int fprintf (FILE *__restrict __stream,
extern int printf (const char *__restrict __format, ...);
extern int sprintf (char *__restrict __s,
extern int vfprintf (FILE *__restrict __s, const char *__restrict __format,
extern int vprintf (const char *__restrict __format, _G_va_list __arg);
&hellip;
        </pre>
        <p>Not code, just a definition</p>
    </div>

    <div class="step" data-x='1846' data-y='840' data-scale="0.2">
        <h2>Symbols in the Binary</h2>
        <pre class="card prettyprint">
+~: readelf -s

Symbol table '.dynsym' contains 4 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND 
     1: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND printf@GLIBC_2.2.5 (2)
     2: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __libc_start_main@GLIBC_2.2.5 (2)
     3: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND __gmon_start__
        </pre>
        <p><code>printf</code> is undefined and has no address</p>
    </div>

    <div class="step" data-x='1846' data-y='940' data-scale="0.2">
        <h2>Symbols in the Library</h2>
        <pre class="card prettyprint">
+~/dev/scratch: readelf -s /lib/x86_64-linux-gnu/libc.so.6 | grep printf
   &hellip;
   596: 00000000000546b0   161 FUNC    GLOBAL DEFAULT   12 printf@@GLIBC_2.2.5
   &hellip;
        </pre>
        <p><code>printf</code> is a global symbol with an address here.</p>
        <p>Running the binary will cause the library to be <b>dynamically</b> loaded and the address of <code>printf</code> will be filled in.
    </div>


    <div class="step" data-x='1366' data-y='1240' data-scale="0.5">
        <h1>JIT/Intepretted</h1>
        <center><img class="naked" src="images/software-interfaces/int-jit.png" /></center>
        <div class="notes">Just-in-time (JIT) compiled code has two processes, one on done before-hand and one done while the program runs. The intermediate representation is called &ldquo;Byte Code&rdquo;</div>
    </div>

    <div class="step" data-x='1306' data-y='1310' data-scale="0.2">
            <p><b>Compiler:</b> Source Code to &ldquo;virtual&rdquo; Assembly (Bytecode)</p>
            <p>Bytecode is like assembly, but not tied to a particular architecture.</p>
        <div class="notes">Bytecode can be run on multiple machines/architectures. It can't run by itself though, it requires runtime support on the target machine.</div>
    </div>

    <div class="step" data-x='1506' data-y='1220' data-scale="0.2">
            <p><b>JIT:</b> Compiles the BC to the platform's Assembly then executes it directly</p>
    </div>

    <div class="step" data-x='1506' data-y='1325' data-scale="0.2">
            <p><b>Interpretted:</b> Parses the BC to find what action to perform, then calls a function to perform the operation.</p>
    </div>

    <div class="step" data-x='1706' data-y='1265' data-scale="0.2">
        <div class="simplecard" style="width:400px;float:left">
        <h3>JIT</h3>
        <ul><li>Slow Compilation</li>
            <li>Fast Execution</li>
            <li>Good Optimization</li>
            <li>JIT hard to port</li></ul>
        </div>
        <div class="notes">The JIT paradigm adds some overhead to the runtime process as the translation from byte code to machine instructions has to be done before the instruction can actually be executed. This sounds like it would take a lot of overhead, but modern JIT compilers might add just a few percent to the execution time. JIT code means that optimization and generation of platform-specific codes are left to the platform itself, the same byte code can then be run on multiple machines. If your Embedded System and your development machine use different architectures, you can still run a single lot of code on both.

The platform itself is also usually in the best position to determine which optimizations to apply, so the overhead of JIT compilation may be reclaimed through smart application of code optimization.</div>
    </div>
    
    <div class="step" data-x='1706' data-y='1265' data-scale="0.2">
        <div class="simplecard" style="width:400px;float:right">
        <h3>Interpretted</h3>
        <ul><li>Fast Parse</li>
            <li>Slow Execution</li>
            <li>Some Optimization</li>
            <li>VM easy to port</li></ul>
        </div>
        <div class="notes">Interpreted code has the same portability advantages as JIT code but because the code is run in a completely controlled and isolated fashion (inside a Virtual Machine), there is the possibility for increased security.

JIT compilers are widely recognized as the future of this kind of technology and are slowly replacing run-time interpreters. One exception is on obscure architectures as Virtual Machines are typically written entirely in C and can be compiled for anything supported by that compiler. JIT compilers have to be written, at least partially, specifically for a target architecture as it has to know which machine instructions to output.</div>
    </div>

    <div class="step" data-x='2106' data-y='1115' data-scale="0.5">
        <h1>Languages</h1>
        <div class="simplecard" style="width:400px;float:left">
            <h3>Compiled</h3>
            <ul><li>C,C++</li>
                <li>ADA</li>
                <li>Fortran</li>
                <li>&hellip;</li></ul>
            <p>Older Languages, low-level code</p>
        </div>
        <div class="simplecard" style="width:400px;float:left">
            <h3>JIT/Interpretted</h3>
            <ul><li>Java</li>
                <li>Python</li>
                <li>Javascript</li>
                <li>&hellip;</li></ul>
            <p>New Languages, portability required.</p>
        </div>

        <div class="notes">Precompiled languages: C, C++, ADA etc. Typically older, more established languages but still very commonly used in Embedded Systems.

Much low-level code such as the Linux Kernel are written in precompiled languages as there isn’t necessarily any platform upon which the JIT compiler or Virtual Machine can run.

JIT languages: Java, .NET, Dalvik since Android 2.2, Python, Javascript in some browsers. Most modern languages were either designed to be interpreted but have subsequently had JIT compilers written, or were designed for JIT execution from the start.

Interpreted languages: Typically older versions of the JIT languages above.</div>
    </div>

    <div class="step" data-x="500" data-y="1366" data-scale="0.5">
        <h1>Speed and Latency</h1>
        <center><img class="naked" src="images/software-interfaces/speed.png" /></center>
        <div class="notes">Speed and Latency are often confused. They are related, but must be specified, and examined, separately</div>
    </div>

    <div class="step" data-x='320' data-y='1396' data-scale="0.2">
    <ul><li>Events</li>
        <li>Data</li>
        <li>&hellip;</li></ul>
        <div class="notes">Embedded Systems <b>always</b> have inputs and outputs. Inputs are things such as events to respond to, data to process etc.</div>
    </div>

    <div class="step" data-x='700' data-y='1396' data-scale="0.2">
        <div style="float:right">
        <ul><li>Response</li>
            <li>Results</li>
            <li>&hellip;</li></ul>
        </div>
        <div class="notes">Outputs are the event responses, processed data etc.</div>
    </div>

    <div class="step" data-x='780' data-y='1336' data-scale="0.2">
        <div class="simplecard" style="float:right">
        <h3>Latency</h3>
        <ul><li><b>Absolute</b> values</li>
            <li>Maximum latency</li>
            <li>Guaranteed throughput</li>
            <li>&hellip;</li></ul>
        </div>
        <div class="simplecard" style="float:right">
        <h3>Speed</h3>
        <ul><li>Average values</li>
            <li>Results per second</li>
            <li>Responses per second</li>
            <li>&hellip;</li></ul>
        </div>
        <div class="notes">Speed in an Embedded System can mean a number of things. In this course, speed will be used primarily as a reference to throughput. That is, “Instructions per second”, “event responses per second” etc.

Responsiveness is related to Real Time concepts as will be presented in a few lectures time. Low latency response, or rather bounded latency response, is a key aspect of all Embedded Systems.  We will assume that any reference to latency is in fact guaranteed or bounded latency; average latency will be referred to in terms of throughput.</div>
    </div>

    <div class="step" data-x='480' data-y='1361' data-scale="0.2">
    <h3>Arbitrate for Speed</h3>
    <ul><li>Low overhead</li>
        <li><b>Fair</b> scheduling</li>
        <li>Target high utilization</li></ul>
        <div class="notes">The most common architectural change to improve speed is to change the management of resources. These might be processor cycles, buffer memory, access to hardware accelerators and so on.

To optimize for speed, the arbiter itself must not take too many resources to run. All tasks are expected to get some access to resources, though the access may be divided differently depending on task priorities.  The resources should never be left unused if possible.</div>
    </div>

    <div class="step" data-x='480' data-y='1431' data-scale="0.2">
    <h3>Arbitrate for Latency</h3>
    <ul><li>Deterministic overhead</li>
        <li><b>Biased</b> scheduling</li>
        <li>Reserved resources</li></ul>

        <div class="notes">Responsiveness is improved by similar means to speed, but with different goals. Rather than increasing the number of available CPU cycles, one might increase the number of CPU Cycles reserved for the particular task.

The overhead need not be low so long as it's predictable.  The scheduling can be biased towards high priority tasks if that's what it takes to meet the required guarantees. The resource can be left unused for a period just in case a high priority event arrives at a particular time.</div>
    </div>


    <!-- Overview pseudo-slide, the data-* elements are filled in by the positioner script -->
	<div id="overview" class="step" data-x="1053" data-y="590.76" data-scale="2.5">&nbsp</div>
</div>


<script src="js/impress.js"></script>
<script src="js/impressConsole.js"></script>
<script src="js/google-code-prettify/prettify.js"></script>
<script src="js/google-code-prettify/lang-verilog.js"></script>
<script>
// Call Impress even if it won't be initialized so we at least
// get .impress-disabled set up and testable from CSS
impress()
prettyPrint()
if ( !window.location.search.match(/print/) ) {
    impress().init();
    impressConsole().init();
}</script>

</body>
</html>

